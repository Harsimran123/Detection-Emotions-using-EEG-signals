{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1vGs-HXUlrz",
        "outputId": "69f00e1d-86a7-4fcd-ced6-e6d86ffc0ddf"
      },
      "source": [
        "!pip install streamlit -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.5MB 8.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 50.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.5MB 30.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 10.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 30.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 30.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 11.2MB/s \n",
            "\u001b[?25h  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.4.3 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "JIfWTUrs2QCn",
        "outputId": "1ece679f-07bf-4e2e-f13f-7badada224c7"
      },
      "source": [
        "!pip install ipykernel~=4.10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipykernel~=4.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/32/b59bdc22fe31cf85750178e486746acc4f6671c2ed798fd8351432637d78/ipykernel-4.10.1-py3-none-any.whl (109kB)\n",
            "\r\u001b[K     |███                             | 10kB 22.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 20kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 30kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 40kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 51kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 61kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 71kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 81kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 92kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 102kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel~=4.10) (5.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel~=4.10) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel~=4.10) (5.3.5)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel~=4.10) (4.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel~=4.10) (51.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel~=4.10) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel~=4.10) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel~=4.10) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel~=4.10) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel~=4.10) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel~=4.10) (4.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel~=4.10) (2.8.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel~=4.10) (20.0.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel~=4.10) (4.7.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel~=4.10) (0.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel~=4.10) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel~=4.10) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipykernel~=4.10) (0.7.0)\n",
            "\u001b[31mERROR: pydeck 0.5.0 has requirement ipykernel>=5.1.2; python_version >= \"3.4\", but you'll have ipykernel 4.10.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: ipykernel\n",
            "  Found existing installation: ipykernel 5.4.3\n",
            "    Uninstalling ipykernel-5.4.3:\n",
            "      Successfully uninstalled ipykernel-5.4.3\n",
            "Successfully installed ipykernel-4.10.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipykernel"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP-qOF_Y2QBT",
        "outputId": "e83d2da2-102a-467c-8a68-d73bf855932b"
      },
      "source": [
        "!pip install folium==0.2.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting folium==0.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/dd/75ced7437bfa7cb9a88b96ee0177953062803c3b4cde411a97d98c35adaf/folium-0.2.1.tar.gz (69kB)\n",
            "\r\u001b[K     |████▊                           | 10kB 18.2MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 20kB 19.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 30kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 40kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 51kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 61kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2 in /usr/local/lib/python3.6/dist-packages (from folium==0.2.1) (2.11.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2->folium==0.2.1) (1.1.1)\n",
            "Building wheels for collected packages: folium\n",
            "  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for folium: filename=folium-0.2.1-cp36-none-any.whl size=79980 sha256=c32c200b63f038c043d5167b37e8e2ed48581ec2096d76ea7d6a6a6c6d0f8f5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/09/f0/52d2ef419c2aaf4fb149f92a33e0008bdce7ae816f0dd8f0c5\n",
            "Successfully built folium\n",
            "Installing collected packages: folium\n",
            "  Found existing installation: folium 0.8.3\n",
            "    Uninstalling folium-0.8.3:\n",
            "      Successfully uninstalled folium-0.8.3\n",
            "Successfully installed folium-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shwCm2GZU5XC",
        "outputId": "11310da7-4074-4651-a8ce-a3b86891db0a"
      },
      "source": [
        "!pip install pyngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/e2/19/af0fc6c11cc13f8a31e9dbec21af745337be8a40b5738cd30f08a483eac3/pyngrok-5.0.1.tar.gz\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyngrok) (3.13)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.0.1-cp36-none-any.whl size=18822 sha256=60fc5f49aa86fc672a2d0129243c90ff791829b024874e660118f80e766b457e\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/01/05/d39efb8f6b40a411354b4168ca9dda99e6f8d586e458e97551\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-5.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtDvfNCKBvuW",
        "outputId": "76d3de1d-16d1-4f82-c755-8b8a23e0dbe7"
      },
      "source": [
        "pip install git+https://github.com/forrestbao/pyeeg.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/forrestbao/pyeeg.git\n",
            "  Cloning https://github.com/forrestbao/pyeeg.git to /tmp/pip-req-build-9846i6ep\n",
            "  Running command git clone -q https://github.com/forrestbao/pyeeg.git /tmp/pip-req-build-9846i6ep\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from pyeeg==0.4.4) (1.19.5)\n",
            "Building wheels for collected packages: pyeeg\n",
            "  Building wheel for pyeeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyeeg: filename=pyeeg-0.4.4-py2.py3-none-any.whl size=28123 sha256=38044940f8d7a22a896eea8faaef4cfadf8a7eabf5329d0339b5a9dea10ccf9e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2jd_thg9/wheels/2d/3f/ad/106d4fc80b61d1ea1fc18e76e7439fd98aa043d83d58eae741\n",
            "Successfully built pyeeg\n",
            "Installing collected packages: pyeeg\n",
            "Successfully installed pyeeg-0.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAiRAoTX24uB",
        "outputId": "6a2a65c8-f236-410b-afca-0eb134ff5047"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFYJioXWYdEA",
        "outputId": "ff0a4803-4b06-471c-a499-078946fd69b0"
      },
      "source": [
        "!pip install plotly==4.5.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting plotly==4.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/e1/88762ade699460dc3229c890f9845d16484a40955a590b65052f0958613c/plotly-4.5.0-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly==4.5.0) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly==4.5.0) (1.15.0)\n",
            "Installing collected packages: plotly\n",
            "  Found existing installation: plotly 4.4.1\n",
            "    Uninstalling plotly-4.4.1:\n",
            "      Successfully uninstalled plotly-4.4.1\n",
            "Successfully installed plotly-4.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffz8hLGgK2iR",
        "outputId": "d8675c2a-a826-4386-d4a0-4f729d37e2f3"
      },
      "source": [
        "%%writefile app.py\n",
        "import pandas as pd \n",
        "import keras.backend as K\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.utils import to_categorical \n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "import timeit\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Flatten, Dense, Dropout\n",
        "from keras.layers.convolutional import Convolution1D, MaxPooling1D, ZeroPadding1D\n",
        "from keras.optimizers import SGD\n",
        "import plotly.express as px\n",
        "#import cv2, numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "@st.cache\n",
        "def get_data():\n",
        "    return (\"pip install git+https://github.com/forrestbao/pyeeg.git\")\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pyeeg as pe\n",
        "import pickle as pickle\n",
        "import pandas as pd\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import normalize\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "random.seed(72)\n",
        "PAGE_CONFIG = {\"page_title\":\"Brain Signal Emotion Recognition\",\"page_icon\":\":brain :\",\"layout\":\"centered\"}\n",
        "st.set_page_config(**PAGE_CONFIG)\n",
        "st.title(\"Emotion Recognition using Brain Signals\")\n",
        "st.markdown(\"The dataset which we have used is [DEAP Dataset](http://www.eecs.qmul.ac.uk/mmv/datasets/deap/)!.\")\n",
        "#st.markdown(\"Streamlit has a handy decorator [`st.cache`](https://streamlit.io/docs/api.html#optimize-performance) to enable data caching.\")\n",
        "#add_selectbox = st.sidebar.selectbox(\"Different Graphs\",(\"Arousal\", \"Dominance\", \"Liking\",\"Valance\"))\n",
        "\n",
        "channel = [1,2,3,4,6,11,13,17,19,20,21,25,29,31] #14 Channels chosen to fit Emotiv Epoch+\n",
        "band = [4,8,12,16,25,45] #5 bands\n",
        "window_size = 256 #Averaging band power of 2 sec\n",
        "step_size = 16 #Each 0.125 sec update once\n",
        "sample_rate = 128 #Sampling rate of 128 Hz\n",
        "subjectList = ['01','02','03']\n",
        "\n",
        "\n",
        "\n",
        "def FFT_Processing (sub, channel, band, window_size, step_size, sample_rate):\n",
        "    meta = []\n",
        "    with open('/content/drive/My Drive/data_preprocessed_python/s' + sub + '.dat', 'rb') as file:\n",
        "\n",
        "        subject = pickle.load(file, encoding='latin1') #resolve the python 2 data problem by encoding : latin1\n",
        "\n",
        "        for i in range (0,40):\n",
        "            # loop over 0-39 trails\n",
        "            data = subject[\"data\"][i]\n",
        "            labels = subject[\"labels\"][i]\n",
        "            start = 0;\n",
        "\n",
        "            while start + window_size < data.shape[1]:\n",
        "                meta_array = []\n",
        "                meta_data = [] #meta vector for analysis\n",
        "                for j in channel:\n",
        "                    X = data[j][start : start + window_size] #Slice raw data over 2 sec, at interval of 0.125 sec\n",
        "                    Y = pe.bin_power(X, band, sample_rate) #FFT over 2 sec of channel j, in seq of theta, alpha, low beta, high beta, gamma\n",
        "                    meta_data = meta_data + list(Y[0])\n",
        "\n",
        "                meta_array.append(np.array(meta_data))\n",
        "                meta_array.append(labels)\n",
        "\n",
        "                meta.append(np.array(meta_array))    \n",
        "                start = start + step_size\n",
        "                \n",
        "        meta = np.array(meta)\n",
        "        np.save('/content/drive/My Drive/data_preprocessed_python/s' + sub, meta, allow_pickle=True, fix_imports=True)\n",
        "\n",
        "for subjects in subjectList:\n",
        "    FFT_Processing (subjects, channel, band, window_size, step_size, sample_rate)\n",
        "\n",
        "data_training = []\n",
        "label_training = []\n",
        "data_testing = []\n",
        "label_testing = []\n",
        "\n",
        "for subjects in subjectList:\n",
        "\n",
        "    with open('/content/drive/My Drive/data_preprocessed_python/s' + subjects + '.npy', 'rb') as file:\n",
        "        sub = np.load(file,allow_pickle=True)\n",
        "        for i in range (0,sub.shape[0]):\n",
        "            if i % 8 == 0:\n",
        "                data_testing.append(sub[i][0])\n",
        "                label_testing.append(sub[i][1])\n",
        "            else:\n",
        "                data_training.append(sub[i][0])\n",
        "                label_training.append(sub[i][1])\n",
        "           \n",
        "#np.save('/content/drive/My Drive/data_preprocessed_python/data_training', np.array(data_training), allow_pickle=True, fix_imports=True)\n",
        "#np.save('/content/drive/My Drive/data_preprocessed_python/label_training', np.array(label_training), allow_pickle=True, fix_imports=True)\n",
        "#print(\"training dataset:\", np.array(data_training).shape, np.array(label_training).shape)\n",
        "\n",
        "np.save('/content/drive/My Drive/data_preprocessed_python/data_testing', np.array(data_testing), allow_pickle=True, fix_imports=True)\n",
        "np.save('/content/drive/My Drive/data_preprocessed_python/label_testing', np.array(label_testing), allow_pickle=True, fix_imports=True)\n",
        "st.info(\"testing dataset : {} , {}\".format(np.array(data_testing).shape, np.array(label_testing).shape))\n",
        "\n",
        "\n",
        "with open('/content/drive/My Drive/data_preprocessed_python/data_testing.npy', 'rb') as fileTrain:\n",
        "    M  = np.load(fileTrain)\n",
        "    \n",
        "with open('/content/drive/My Drive/data_preprocessed_python/label_testing.npy', 'rb') as fileTrainL:\n",
        "    N  = np.load(fileTrainL)\n",
        "\n",
        "M = normalize(M)\n",
        "L = np.ravel(N[:, [1]])\n",
        "A = np.ravel(N[:, [0]])\n",
        "B = np.ravel(N[:, [2]])\n",
        "C = np.ravel(N[:, [3]])\n",
        "\n",
        "Arousal_Test = np.ravel(N[:, [0]])\n",
        "Valence_Test = np.ravel(N[:, [1]])\n",
        "Domain_Test = np.ravel(N[:, [2]])\n",
        "Like_Test = np.ravel(N[:, [3]])\n",
        "x_test = np.array(M[:])\n",
        "from keras.utils import to_categorical\n",
        "y_test1 = to_categorical(L)\n",
        "y_test2 = to_categorical(A)\n",
        "y_test3 = to_categorical(B)\n",
        "y_test4 = to_categorical(C)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_test = scaler.fit_transform(x_test)\n",
        "x_test1 = x_test.reshape(x_test.shape[0],x_test.shape[1], 1)\n",
        "x_test2 = x_test.reshape(x_test.shape[0],x_test.shape[1], 1)\n",
        "x_test3 = x_test.reshape(x_test.shape[0],x_test.shape[1], 1)\n",
        "x_test4 = x_test.reshape(x_test.shape[0],x_test.shape[1], 1)\n",
        "\n",
        "from keras.models import load_model\n",
        "valence_model = load_model('/content/drive/My Drive/data_preprocessed_python/all models with weights (1)/modeel_valence.h5')\n",
        "liking_model = load_model('/content/drive/My Drive/data_preprocessed_python/all models with weights (1)/modeel_liking.h5')\n",
        "Dominance_model = load_model('/content/drive/My Drive/data_preprocessed_python/all models with weights (1)/modeel_dominance.h5')\n",
        "Arousal_model = load_model('/content/drive/My Drive/data_preprocessed_python/all models with weights (1)/modeel_AROUSAL.h5')\n",
        "st.subheader('Different psycological parameters :')\n",
        "if (st.checkbox(\"Valence\", key='chk_Unique_item')):\n",
        "  st.markdown(\">Valence, or hedonic tone, is the affective quality referring to the intrinsic attractiveness goodness (positive valence) or badness (negative valence) of an event, object, or situation. The term also characterizes and categorizes specific emotions. For example, emotions popularly referred to as negative, such as anger and fear, have negative valence. Joy has positive valence. Positively valenced emotions are evoked by positively valenced events, objects, or situations. [Checkout for more](https://en.wikipedia.org/wiki/Valence_(psychology)).\")\n",
        "  valence_score = valence_model.evaluate(x_test1, y_test1, verbose=1)\n",
        "  st.info('Emotional Valence is {:.3f}'.format(valence_score[1]*0.3))\n",
        "  if (valence_score[1]*3>0 and valence_score[1]*3<=1):\n",
        "    st.info('Person have low valence that is you are nervous and sad.')\n",
        "  elif (valence_score[1]*3>1 and valence_score[1]*3<=2):\n",
        "    st.info('Person have low valence that is you are bored and angry.')\n",
        "  elif (valence_score[1]*3>2 and valence_score[1]*3<=3):\n",
        "    st.info('Person is not sad or happy')\n",
        "  elif (valence_score[1]*3>3 and valence_score[1]*3<=4):\n",
        "    st.info('Person have high valence that is you are happy and peaceful.')\n",
        "  else :\n",
        "    st.info('Person have high valence that is you are pleased and relaxed.')\n",
        "elif (st.checkbox(\"Arousal\", key='chk_Unique_item1')) :\n",
        "  st.markdown(\">Arousal is important in regulating consciousness, attention, alertness, and information processing. It is crucial for motivating certain behaviours, such as mobility, the pursuit of nutrition, the fight-or-flight response and sexual activity (the arousal phase of Masters and Johnson's human sexual response cycle). It is also important in emotion and has been included in theories such as the James-Lange theory of emotion. According to Hans Eysenck, differences in baseline arousal level lead people to be extraverts or introverts. [Checkout for more](https://en.wikipedia.org/wiki/Arousal).\")\n",
        "  arousal_score = Arousal_model.evaluate(x_test2, y_test2, verbose=1)\n",
        "  st.info('Emotional Arosual is {:.3f}'.format(arousal_score[1]*0.75))\n",
        "  if (arousal_score[1]*3>0 and arousal_score[1]*3<=1):\n",
        "    st.info('Person has low arousal that is you are tired.')\n",
        "  elif (arousal_score[1]*3>1 and arousal_score[1]*3<=2):\n",
        "    st.info('Person has low arousal that is you are dropy.')\n",
        "  elif (arousal_score[1]*3>2 and arousal_score[1]*3<=3):\n",
        "    st.info('Person is not aroused')\n",
        "  elif (arousal_score[1]*3>3 and arousal_score[1]*3<=4):\n",
        "    st.info('Person have high arousal that is you are curious.')\n",
        "  else :\n",
        "    st.info('You have high valence that is you are surprised.')\n",
        "elif (st.checkbox(\"Dominance\", key='chk_Unique_item2')) :\n",
        "  st.markdown(\">Dominance is a characteristic of highly social animals, such as humans, in which individuals of the same species compete intensely with one another for food, mates, territory, or any other resource, including money. In highly social species, individuals establish social relationships with their family members, sexual partners, friends and enemies, and co-workers and competitors. [Checkout for more](https://www.psychologytoday.com/intl/blog/games-primates-play/201203/social-dominance-explained-part-i#:~:text=Dominance%20is%20established%20within%20a,he%20gets%20what%20he%20wants.)\")\n",
        "  dominance_score = Dominance_model.evaluate(x_test3, y_test3, verbose=1)\n",
        "  st.info('Emotional Dominance is {:.3f}'.format(dominance_score[1]*0.5))\n",
        "elif (st.checkbox(\"Liking\", key='chk_Unique_item3')) :\n",
        "  st.markdown(\">Reciprocity of liking (also known as reciprocity of attraction and reciprocal liking) describes the tendency for individuals to think positively of others who express positive regard for them. Essentially, we like people who say that they like us. Individuals are more likely to like someone who expresses that they like them. When you learn that someone has expressed liking us we are more likely to have positive feelings for that person. This doesn't work all the time though. Research has shown that people who don't like themselves (have low self esteem) don't like people who like them.\")\n",
        "  liking_score = liking_model.evaluate(x_test4, y_test4, verbose=1)\n",
        "  st.info('Emotional Liking is {:.3f}'.format(liking_score[1]*0.54))\n",
        "elif (st.checkbox(\"Full Analysis\", key='chk_Unique_item4')) :\n",
        "  valence_score = valence_model.evaluate(x_test1, y_test1, verbose=1)\n",
        "  liking_score = liking_model.evaluate(x_test4, y_test4, verbose=1)\n",
        "  arousal_score = Arousal_model.evaluate(x_test2, y_test2, verbose=1)\n",
        "  dominance_score = Dominance_model.evaluate(x_test3, y_test3, verbose=1)\n",
        "  st.info('Magnitude Emotional Arosual is {:.3f}'.format(arousal_score[1]*0.75))\n",
        "  st.info('Magnitude Emotional Dominance is {:.3f}'.format(dominance_score[1]*0.5))\n",
        "  st.info('Magnitude Emotional Valence is {:.3f}'.format(valence_score[1]*0.3))\n",
        "  st.info('Magnitude Emotional Liking is {:.3f}'.format(liking_score[1]*0.54))\n",
        "  st.markdown(\"EMOTION ANALYSIS OF A CONCERENED PERSON\")\n",
        "  if ((valence_score[1]*0.3>0 and valence_score[1]*0.3<1) or (arousal_score[1]*0.75>0 and arousal_score[1]*0.75<1)):\n",
        "    st.info('The Person tested is negative valence and low arousal including low dominance that means your emotion state right now is depressed.The Person needs to consult and psychologist urgently.')\n",
        "  elif ((valence_score[1]*0.3>0 and valence_score[1]*0.3<1) or (arousal_score[1]*0.75>1 and arousal_score[1]*0.75<2)):\n",
        "    st.info('The Person tested is negative valence and low arousal that means your emotion state right now is bored and dropy.The Person needs to rest and think positive.')\n",
        "  elif ((valence_score[1]*0.3>1 and valence_score[1]*0.3<2) or (arousal_score[1]*0.75>1 and arousal_score[1]*0.75<2)):\n",
        "    st.info('The Person tested is partially negative valence and comparatively low arousal that means your emotion state right now is anger and dropy.The Person needs to stop taking stress and think positive.')\n",
        "  elif ((valence_score[1]*0.3>3 and valence_score[1]*0.3<4) or (arousal_score[1]*0.75>2 and arousal_score[1]*0.75<3)):\n",
        "    st.info('The Person tested is positive valence that means your emotion state right now is happy and peaceful.The Person is in positive state of mind.')\n",
        "  elif ((valence_score[1]*0.3>4 and valence_score[1]*0.3<5) or (arousal_score[1]*0.75>3 and arousal_score[1]*0.75<4)):\n",
        "    st.info('The Person tested is positive valence and high arousal that means your emotion state right now is plaesed and surprised.The Person is in positive state of mind.')\n",
        "  else:\n",
        "    st.info('You have high dominance and positive liking that means your emotion state right now is admiration.You are in positive state of mind.')\n",
        "  st.markdown(\"YOUR EMOTION CHART\")\n",
        "  data = dict(\n",
        "    character=[\"Valence\",\"Arousal\",\"Liking\",\"Dominance\",\"Final Valence\",\"Final Arousal\",\"Final Liking\",\"Final Dominance\"],\n",
        "    parent=[\"\",\"\",\"\",\"\",\"Valence\",\"Arousal\",\"Liking\",\"Dominance\"],\n",
        "    value=[1,1,1,1,valence_score[1]*0.3,arousal_score[1]*0.75,liking_score[1]*0.54,dominance_score[1]*0.5])\n",
        "  fig =px.sunburst(\n",
        "      data,\n",
        "      names='character',\n",
        "      parents='parent',\n",
        "      values='value',\n",
        "  )\n",
        "  st.plotly_chart(fig)\n",
        "\n",
        "st.text_area('Feedback incase of any problem faced')\n",
        "\n",
        "st.markdown(\"Process Completed !\")\n",
        "st.write(\"Yay! The Emotional Analysis of Person is Done !.\")\n",
        "btn = st.button(\"Celebrate!\")\n",
        "if btn:\n",
        "    st.balloons()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfkOTF2DVzIU",
        "outputId": "d5524638-c69c-47de-8651-2cae95e4327f"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "app.py\tdrive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG6TJy2U27Gp"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WOco3BUV3br",
        "outputId": "5c9702a5-d42c-45d3-aab9-8123c5580ad5"
      },
      "source": [
        "!ngrok authtoken 1k3Iz8yRHTSAnSvHXBfXUp0gY7p_2DaQvtfbUsHKoM26AdXjG"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbQeHmFjWZrp",
        "outputId": "a1dec4fd-d45c-43c2-8651-988e9bdaa00f"
      },
      "source": [
        "!nohub streamlit run app.py\n",
        "from pyngrok import ngrok\n",
        "!pyngrok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: nohub: command not found\n",
            "NAME:\n",
            "   ngrok - tunnel local ports to public URLs and inspect traffic\n",
            "\n",
            "DESCRIPTION:\n",
            "    ngrok exposes local networked services behinds NATs and firewalls to the\n",
            "    public internet over a secure tunnel. Share local websites, build/test\n",
            "    webhook consumers and self-host personal services.\n",
            "    Detailed help for each command is available with 'ngrok help <command>'.\n",
            "    Open http://localhost:4040 for ngrok's web interface to inspect traffic.\n",
            "\n",
            "EXAMPLES:\n",
            "    ngrok http 80                    # secure public URL for port 80 web server\n",
            "    ngrok http -subdomain=baz 8080   # port 8080 available at baz.ngrok.io\n",
            "    ngrok http foo.dev:80            # tunnel to host:port instead of localhost\n",
            "    ngrok http https://localhost     # expose a local https server\n",
            "    ngrok tcp 22                     # tunnel arbitrary TCP traffic to port 22\n",
            "    ngrok tls -hostname=foo.com 443  # TLS traffic for foo.com to port 443\n",
            "    ngrok start foo bar baz          # start tunnels from the configuration file\n",
            "\n",
            "VERSION:\n",
            "   2.3.35\n",
            "\n",
            "AUTHOR:\n",
            "  inconshreveable - <alan@ngrok.com>\n",
            "\n",
            "COMMANDS:\n",
            "   authtoken\tsave authtoken to configuration file\n",
            "   credits\tprints author and licensing information\n",
            "   http\t\tstart an HTTP tunnel\n",
            "   start\tstart tunnels by name from the configuration file\n",
            "   tcp\t\tstart a TCP tunnel\n",
            "   tls\t\tstart a TLS tunnel\n",
            "   update\tupdate ngrok to the latest version\n",
            "   version\tprint the version string\n",
            "   help\t\tShows a list of commands or help for one command\n",
            "\n",
            "PYNGROK VERSION:\n",
            "   5.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-wSIaqGWlfQ"
      },
      "source": [
        "\n",
        "!streamlit run --server.port 80 app.py&>/dev/null&"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF-GMecQXCmf",
        "outputId": "2489fd22-7690-4039-8ea2-fffd006f9eef"
      },
      "source": [
        "!pgrep streamlit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu7u2aw8XHnU"
      },
      "source": [
        "public_url = ngrok.connect(port='8501')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13qjTbiJXS98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a84c4771-f5e4-45b1-b39e-3bba00351660"
      },
      "source": [
        "public_url"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"http://3e24b95f8ea9.ngrok.io\" -> \"http://localhost:80\">"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyFX-R61ceDY"
      },
      "source": [
        "!kill 798\n",
        "ngrok.kill()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab50wZgXPJDq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}